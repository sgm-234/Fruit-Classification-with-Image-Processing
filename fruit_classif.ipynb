{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmZXXoCJSLnc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYfDbGQxSZ3Y"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "!unzip \"/content/drive/MyDrive/fruits.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BotUQ-PuSoit"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-DJF1F3cqut"
      },
      "outputs": [],
      "source": [
        "#Data and directory summary after unnecessary data has been deleted\n",
        "import os\n",
        "for dirpath,dirname,filenames in os.walk(\"train\"):\n",
        "  print(f\"There are {len(dirname)} directories and {len(filenames)} images in {dirpath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t29JWcxUTh1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import pathlib\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETMxcCwIdE1n"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(\"/content/train/train\")\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP9TnbDrUVZq"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/train/train',output=\"/content/Fruits\",seed=42,ratio=(0.8,0.1,0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju22lTpldcD6"
      },
      "outputs": [],
      "source": [
        "#setting up the path for training,validation and testing directories\n",
        "train_dir=\"/content/Fruits/train\"\n",
        "test_dir=\"/content/Fruits/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSXALY_mdwX3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "augment_datagen = ImageDataGenerator(rotation_range=20,\n",
        "                         width_shift_range=0.2,\n",
        "                         height_shift_range=0.2,\n",
        "                         rescale=1/255.,\n",
        "                         shear_range=0.2,\n",
        "                         zoom_range=0.2,\n",
        "                         horizontal_flip=True,)\n",
        "test_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "train_data=augment_datagen.flow_from_directory(train_dir,\n",
        "                                             target_size=(100,100),\n",
        "                                             batch_size=64,\n",
        "                                             class_mode=\"categorical\",\n",
        "                                             shuffle=True)\n",
        "test_data=test_datagen.flow_from_directory(test_dir,\n",
        "                                           target_size=(100,100),\n",
        "                                           batch_size=64,\n",
        "                                           class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgl8Si8heB5q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_loss_curves(history):\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNN_WAsCeE-a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top (fully connected) layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(100,100,3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "VGG16_model=Sequential()\n",
        "VGG16_model.add(base_model)\n",
        "\n",
        "\n",
        "VGG16_model.add(Flatten())\n",
        "VGG16_model.add(Dense(512, activation='relu'))\n",
        "VGG16_model.add(Dropout(0.5))\n",
        "VGG16_model.add(Dense(33, activation='softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "VGG16_model.summary()\n",
        "\n",
        "# Compile the model\n",
        "VGG16_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_VGG16 = VGG16_model.fit(train_data,\n",
        "                          epochs=1,\n",
        "                          steps_per_epoch=len(train_data),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UzquoayeXva"
      },
      "outputs": [],
      "source": [
        "VGG16_model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHuh60Cf3aTe"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "def load_and_prep_image(filename, img_shape=100):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor\n",
        "  and reshapes it to (img_shape, img_shape, colour_channel).\n",
        "  \"\"\"\n",
        "\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor & ensure 3 colour channels\n",
        "  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S8MB_tuw62s"
      },
      "outputs": [],
      "source": [
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWMEU8bYxID8"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(VGG16_model,\"/content/Fruits/test/Cherry/Cherry_100.jpg\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytWkkoMXxZhA"
      },
      "outputs": [],
      "source": [
        "VGG16_model.save(\"FruitDetector.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnvvcDoi4v7H"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(\"FruitDetector.h5\")\n",
        "loaded_model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmIdwbAf5Dlp"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(VGG16_model,\"/content/Banana.jpg\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZqPugebuYeo"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(VGG16_model,\"/content/watermleon.jpg\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22VntuNvvDKD"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(VGG16_model,\"/content/Lemon.jpg\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da0xOeDdvaPE"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(VGG16_model,\"/content/Pomegranate.jpg\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svGlhPYNvxbJ"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(VGG16_model,\"/content/corn_sample.jpg\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tviVPwOP5Zx5"
      },
      "outputs": [],
      "source": [
        "VGG16_model.save(\"FruitDetector.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8fXne2H2ljt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "loaded_model = tf.keras.models.load_model(\"FruitDetector.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXn5O5vO5LBZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('FruitDetector.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}